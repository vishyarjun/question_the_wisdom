{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0d0aae-9e0b-49eb-8470-77b75fa39a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step0: load openAI key\n",
    "import os\n",
    "import sys\n",
    "import openai\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd2e5eb-edef-4477-9b61-97ffe536992f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n"
     ]
    }
   ],
   "source": [
    "#step1: Load the document using PyPDFLoader - there are other options to load as well.\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"gita_english_full.pdf\")\n",
    "pages = loader.load()\n",
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cc024a-cf5a-4e7e-8343-df1fad232255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\"Bhagavad-gita As It Is \" \\nby His Divine Grace A.C. Bh aktivedanta Swami Prabhupada. \\n \\nCOPYRIGHT NOTICE:  \\n \\nThis is an evaluation copy  of the printed version of this book, and is NOT FOR \\nRESALE . This evaluation copy is intended  for personal non-commercial use only, \\nunder the \"fair use\" guidelines establishe d by international copyright laws. You \\nmay use this electronic file to evaluate the printed version of this book, for your \\nown private use, or for short excerpts us ed in academic works,  research, student \\npapers, presentations, and the like. You ca n distribute this evaluation copy to \\nothers over the Internet, so long as you keep  this copyright information intact and \\ndo not add or subtract anything to this f ile and its contents. You may not reproduce \\nmore than ten percent (10%) of this book in any medium without the express \\nwritten permission from the copyright holders. \\n \\nReference any excerpts in the follo wing way: “Excerpted from “Srimad \\nBhagavatam Tenth Canto Part One” by A.C. Bhaktivedanta Swami Prabhupada, \\ncourtesy of the Bhaktivedanta  Book Trust International, www.krishna.com .” \\n \\nThis book and electronic file is Copyri ght 1972-2004 Bhaktivedanta Book Trust \\nInternational, 3764 Watsek a Avenue, Los Angeles, California 90034, USA. All \\nrights reserved. For any questions, comme nts, correspondence, or to evaluate \\ndozens of other books in this collection, visit the website of the publishers, \\nwww.krishna.com .' metadata={'source': 'gita_english_full.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "#step2: Split the text into chunks that can be stored\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(pages)\n",
    "len(splits)\n",
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c83748c-325e-438a-aa81-e5da089d4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3: Use vector store chroma, store the embeddings to disk - there are multiple vectorDB that can be used.\n",
    "\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents = splits,\n",
    "    embedding = embedding,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d6d2b7-98f0-4eec-b2b8-ea58b64dce2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/embeddings/huggingface.py:50\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sentence_transformers/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sentence_transformers/datasets/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sentence_transformers/datasets/DenoisingAutoEncoderDataset.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/__init__.py:229\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    228\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Arjun/opt/anaconda3/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so, 2): Library not loaded: @loader_path/libtorch_cpu.dylib\n  Referenced from: /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_python.dylib\n  Reason: image not found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m      4\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m Chroma(\n\u001b[0;32m----> 5\u001b[0m     embedding_function \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain/embeddings/huggingface.py:53\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`."
     ]
    }
   ],
   "source": [
    "#load vectorDB incase of running it for 2nd 3rd time etc, as we don't have to write it into DB everytime.\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "vectordb = Chroma(\n",
    "    embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7cccd0-56f1-4005-8061-cfb860790b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (1.7.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (1.22.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (4.31.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: scikit-learn in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: nltk in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.2.0)\n",
      "Requirement already satisfied: filelock in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: requests in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (2.11.3)\n",
      "Requirement already satisfied: sympy in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (2.7.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: click in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Arjun/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c109dafe-bbf5-44f1-877c-be81be96e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are things that human should not involve in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19f5c04-b332-46f5-a4b5-f992c4ad2bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectordb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Invoke Max Marginal Relevance with Vector Store\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mvectordb\u001b[49m\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(question,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectordb' is not defined"
     ]
    }
   ],
   "source": [
    "# Invoke Max Marginal Relevance with Vector Store\n",
    "docs = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ce98ef-8f40-4a1f-8306-668d0f429a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step4: Applying Compression techniques to improve quality of extracted text\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f108a5-082e-458d-b73a-210e1a24a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arjun/opt/anaconda3/lib/python3.9/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "# Invoke Compressor for better quality output from source document\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6572e53-5764-42c1-8d3a-c752ffeab644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\"One who can see that all activities are performed by the body, which is created of material nature, and sees that the self does nothing, actually sees.\" \"The self, however, is outside all these bodily activities.\" \"One who has such a vision is an actual seer.\"', metadata={'page': 799, 'source': 'gita_english_full.pdf'}), Document(page_content='\"Not only Arjuna, but every one of us is full of anxieties because of this material existence. Our very existence is in the atmosphere of nonexistence. Actually we are not meant to be threatened by nonexistence. Our existence is eternal. But somehow or other we are put into asat. Asat refers to that which does not exist. Out of so many human beings who are suffering, there are a few who are actually inquiring about their position, as to what they are, why they are put into this awkward position and so on. Unless one is awakened to this position of questioning his suffering, unless he realizes that he doesn’t want suffering but rather wants to make a solution to all suffering, then one is not to be considered a perfect human being. Humanity begins when this sort of inquiry is awakened in one’s mind.\"', metadata={'page': 13, 'source': 'gita_english_full.pdf'}), Document(page_content='\"Social work, nationalism and altruism are some of the activities for such materially designated persons.\"', metadata={'page': 239, 'source': 'gita_english_full.pdf'}), Document(page_content='\"Humanity may be divided into two sections, namely, the regulated and the nonregulated. Those who are engaged simply in bestial sense gratifications without knowledge of their next life or spiritual salvation belong to the nonregulated section.\"', metadata={'page': 424, 'source': 'gita_english_full.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dd83b-b4e8-4f96-98f6-1dd63cbea875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Retrieval QA chain to pass context and receive response from LLM\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "result = qa_chain_mr({\"query\": question})\n",
    "result[\"result\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3300ed6a-7db3-41d0-9af3-fc0b70da8868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Human should not involve in activities that are based on material nature, such as social work, nationalism, and altruism. They should instead focus on spiritual activities and understanding the nature of the Absolute. Thanks for asking!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16ecfe-f06e-499c-b381-1c4319548dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0fc04b-78a8-4eb7-a5af-182fcf738a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 adding a layer of memory\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cad78c5-9858-4b78-84ec-7725d07cc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c747ed-f065-473b-8498-b1f86c48ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The purpose of life is to reach the eternal kingdom of God, either merging into the impersonal Brahman or associating with the Supreme Personality of Godhead, Kåñëa.\n"
     ]
    }
   ],
   "source": [
    "q1 = \"What is the purpose of life?\"\n",
    "result = qa({\"question\": q1})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1084c408-c551-4c1d-84ed-6ff2bf49081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The purpose of life is to advance toward the supreme eternal atmosphere. This is done by controlling the senses, becoming cleansed of the sinful reactions of material existence, and entering into the eternal kingdom of God, either merging into the impersonal Brahman or associating with the Supreme Personality of Godhead, Kåñëa.\n"
     ]
    }
   ],
   "source": [
    "q2 = \"Explain that in detail.\"\n",
    "result = qa({\"question\": q2})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea8d3010-03ec-4a99-a07f-2bdd9f0f5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-rDa5o8yXsO2QiirJG0nLT5ZQ on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can advance towards the supreme eternal atmosphere by attaining to the Supreme Personality of Godhead. This can be done by following the instructions of the Bhagavad-gétä, such as remembering the Supreme at the time of death and attaining to His abode.\n"
     ]
    }
   ],
   "source": [
    "q3 = \"How to advance towards it.\"\n",
    "result = qa({\"question\": q3})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0fa705d-c972-4b10-9fb6-31657c56f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To advance towards the supreme eternal atmosphere, one must attain to the Supreme Personality of Godhead. This can be done by cultivating spiritual knowledge, in eternal relationship with the Supreme Personality of Godhead, and by devoting oneself to the Lord. At the time of death, whoever thinks of the Lord as Brahman, Paramatma, or the Personality of Godhead, will enter the spiritual sky.\n"
     ]
    }
   ],
   "source": [
    "q4 = \"Explain that in detail.\"\n",
    "result = qa({\"question\": q4})\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
